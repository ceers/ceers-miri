{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b49ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sep\n",
    "import multiprocessing\n",
    "\n",
    "import pyregion\n",
    "from astropy.convolution import Tophat2DKernel\n",
    "from scipy.ndimage import binary_dilation\n",
    "from astroscrappy import detect_cosmics\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61048319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The super-bkg method\n",
    "def rm_strip(cal_file, rm_hz=False, rm_vt=False):\n",
    "    with datamodels.open(cal_file) as dm:\n",
    "        # Read science image and build weight\n",
    "        sci_img = dm.data.copy()\n",
    "        err_map = dm.err.copy()\n",
    "        #wht = build_driz_weight(dm, weight_type='ivm', good_bits='~DO_NOT_USE+NON_SCIENCE')\n",
    "        #mask = (wht==0)\n",
    "        # Mask bad pixels\n",
    "        mask = (np.isfinite(err_map)==False) | (dm.dq>4)\n",
    "        err_map[mask] = np.inf\n",
    "        # Get the global bkg values\n",
    "        glob_bkg = get_glob_bkg(sci_img, err_map)\n",
    "        # Subtract horizontal stripping\n",
    "        if rm_hz:\n",
    "            hz_strips = sigma_clipped_stats(sci_img, mask=mask, sigma=2, cenfunc='median', stdfunc='std', axis=1)[1]\n",
    "            sci_img = (sci_img.T-hz_strips).T\n",
    "        # Subract vertical stripping\n",
    "        if rm_vt:\n",
    "            vt_strips = sigma_clipped_stats(sci_img, mask=mask, sigma=2, cenfunc='median', stdfunc='std', axis=0)[1]\n",
    "            sci_img -= vt_strips\n",
    "        # If not horizontal nor vertical, subtract a constant global background\n",
    "        if (rm_hz or rm_vt)==False:\n",
    "            sci_img -= glob_bkg\n",
    "        else:\n",
    "            # Set all nan (may be caused by strip removal)\n",
    "            mask[np.isnan(sci_img)] = True\n",
    "            sci_img[np.isnan(sci_img)] = 0\n",
    "            err_map[mask] = np.inf\n",
    "        # Replace the old data\n",
    "        dm.data = sci_img\n",
    "        #dm.err = err_map\n",
    "        dm.save(cal_file.replace('.fits','')+'_stprm.fits', overwrite=True)\n",
    "    return glob_bkg\n",
    "        \n",
    "def get_glob_bkg(dat, err):\n",
    "    mask = (np.isfinite(err)==False)\n",
    "    mask[:,:300]=True\n",
    "    mask[:,1026:]=True\n",
    "    ok = (mask==False)\n",
    "    med_global = np.nanmedian(dat.astype('float')[ok])\n",
    "    return med_global\n",
    "\n",
    "def det_src(img, sigma_threshold=2, bw=72, bh=72, fw=5, fh=5,\n",
    "            clean_edge=True, cr_sigclip=1., minarea=5, r_dilate=-1,\n",
    "            kernel=np.array([[1,2,1], [2,4,2], [1,2,1]])):\n",
    "    # mask_threshold=0.3, no longer used\n",
    "    # Open data model\n",
    "    #with datamodels.open(img) as dm:\n",
    "        # Read science image and build weight\n",
    "        #dat = dm.data.copy()\n",
    "        #wht = build_driz_weight(dm, weight_type='ivm', good_bits='~DO_NOT_USE+NON_SCIENCE')\n",
    "        # subtract a constant background first \n",
    "        # This is no longer needed becuase we remove the stripes before\n",
    "        #dat -= get_glob_bkg(dat, dm.err)\n",
    "    \n",
    "    # Check input type\n",
    "    if type(img) == str:\n",
    "        # Read data\n",
    "        dat = fits.getdata(img, 'sci')\n",
    "        err = fits.getdata(img, 'err')\n",
    "        dq = fits.getdata(img, 'dq')\n",
    "    elif type(img) == jwst.datamodels.ImageModel:\n",
    "        dat = img.data.copy()\n",
    "        err = img.err.copy()\n",
    "        dq = img.dq.copy()\n",
    "    # Mask cosmic rays\n",
    "    cr_map = detect_cosmics(dat, sigclip=cr_sigclip)[0]*1\n",
    "    err[np.where(cr_map)] = np.inf\n",
    "    err[dq>4] = np.inf\n",
    "    # subtract a background, then find objects.     \n",
    "    #mask = (wht < np.max(wht)* mask_threshold) \n",
    "    wht = 1./err**2\n",
    "    mask = (np.isfinite(err)==False)\n",
    "    wht[mask] = np.nan\n",
    "    wht /= np.nanmedian(wht)\n",
    "    # Estimate a spatial dependent background\n",
    "    bkg = sep.Background(dat.astype('float'), mask=mask, bw=bw, bh=bh, fw=fw, fh=fh)\n",
    "    bkg.back()[mask] = np.nan\n",
    "    # identify objects\n",
    "    wdat = (dat-bkg.back())  * wht\n",
    "    wdat[mask] = np.nan\n",
    "    wbkg = sep.Background(wdat, mask=mask, bw=bw, bh=bh, fw=fw, fh=fh)  \n",
    "    objects = sep.extract(wdat, sigma_threshold, mask=mask, filter_kernel=kernel,\n",
    "                          err=wbkg.globalrms, segmentation_map=True, minarea=minarea)\n",
    "    src, seg = objects[0], objects[1]\n",
    "    # Convert src to astropy table format\n",
    "    src = Table(src)\n",
    "    # Add an ID column \n",
    "    src.add_column( np.arange(len(src))+1, name='id' )\n",
    "    # Clean sources close to detector edge if needed\n",
    "    if clean_edge: \n",
    "        # Read the bad master region file\n",
    "        regs = pyregion.open(\"../data/master_noisy_region.reg\")\n",
    "        # Iterate over each bad region\n",
    "        bad_src_idxs = []\n",
    "        for reg in regs:\n",
    "            # Get the four points\n",
    "            x1, x2 = reg.coord_list[0]-reg.coord_list[2]/2, reg.coord_list[0]+reg.coord_list[2]/2\n",
    "            y1, y2 = reg.coord_list[1]-reg.coord_list[3]/2, reg.coord_list[1]+reg.coord_list[3]/2\n",
    "            # Get sources in the region\n",
    "            bad_src_idxs = np.append(bad_src_idxs,\n",
    "                    np.where( (src['x']>x1) & (src['x']<x2) & (src['y']>y1) & (src['y']<y2) )[0] )\n",
    "        bad_src_idxs = np.sort(np.unique(bad_src_idxs)).astype(int)\n",
    "        # Remove the bad sources in both catalog and segmentaion\n",
    "        good_src_idxs = np.delete(np.arange(len(src)), bad_src_idxs)\n",
    "        src = src[good_src_idxs]\n",
    "        for bad_id in bad_src_idxs+1:\n",
    "            seg[seg==bad_id] = 0\n",
    "    # Dilate the segmentaion? (but all pixel will be set to 1)\n",
    "    if r_dilate>0:\n",
    "        footprint = Tophat2DKernel(radius=r_dilate)\n",
    "        seg = binary_dilation(seg, footprint.array).astype(int)\n",
    "            \n",
    "    return src, dat, wht, bkg, seg\n",
    "\n",
    "def super_bg(files, sigma_threshold=2, bw=72, bh=72, fw=5, fh=5, minarea=20,\n",
    "             kernel=np.array([[1,2,1], [2,4,2], [1,2,1]]), r_dilate=10,\n",
    "             clean_edge=True, write_bg=False):\n",
    "    # read in each image.  Identify objects and mask with background from SEP\n",
    "    x, y = np.shape( fits.getdata(files[0]) )\n",
    "    darr = np.zeros( [len(files), x, y] )\n",
    "    # Check number of files \n",
    "    if len(files)<2:\n",
    "        raise Exception(\"Too few input files?!\")\n",
    "    elif len(files)==2:\n",
    "        print('Warning: building master background from a single file')\n",
    "        # Use different parameters if building from a single image\n",
    "        clean_edge = False\n",
    "        r_dilate = -1\n",
    "        minarea = 5\n",
    "        sigma_threshold = 1.2\n",
    "    else:\n",
    "        print('Building master background from a %d files' %(len(files)-1))\n",
    "    # Iterate over each file to get the background     \n",
    "    for i,f in enumerate(files):\n",
    "        # Detect sources \n",
    "        src, dat, wht, bkg, seg = det_src(f, sigma_threshold=sigma_threshold,\n",
    "            r_dilate=r_dilate, bw=bw, bh=bh, fw=fw, fh=fh, cr_sigclip=1.,\n",
    "            minarea=minarea, kernel=kernel, clean_edge=clean_edge)\n",
    "        print(\"%d src detected!\" %len(src))\n",
    "        # Fill in NaN or bkg, depending on number of files available\n",
    "        if len(files)>2:\n",
    "            dat[seg > 0] = np.nan\n",
    "        else:\n",
    "            dat[seg > 0] = bkg.back()[seg > 0]        \n",
    "        # Save the data\n",
    "        darr[i] = dat\n",
    "    # Subtract background for each file\n",
    "    for idx0, f0 in enumerate(files):\n",
    "        #take median \n",
    "        oth_idxs = np.delete(range(len(files)), idx0)\n",
    "        dmed = np.nanmedian(darr[oth_idxs], axis=0)\n",
    "        # Set nan to 0 to avoid NaN in the result\n",
    "        dmed[np.isnan( dmed )] = 0\n",
    "        # subtract and writeout\n",
    "        with fits.open(f0) as hdu:\n",
    "            # Subtract the background\n",
    "            hdu['sci'].data -= dmed\n",
    "            mask = (np.isfinite(hdu['err'].data)==False) | np.isnan(hdu['sci'].data) | hdu['dq'].data>4\n",
    "            hdu['sci'].data[mask] = 0\n",
    "            hdu['err'].data[mask] = np.inf\n",
    "            hdu.writeto( f0.replace('.fits','')+'_bgsub.fits', overwrite=True)\n",
    "            # Write background if needed\n",
    "            if write_bg: \n",
    "                hdu['sci'].data = dmed\n",
    "                hdu.writeto( f0.replace('.fits','')+'_bg.fits', overwrite=True)\n",
    "        print(f0.replace('.fits','')+'_bgsub.fits' + \"  Done!\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e4c09",
   "metadata": {},
   "source": [
    "%run -i './group_imgs.ipynb'\n",
    "from glob import glob\n",
    "import os\n",
    "output_dir = \"../data/reduced/\"\n",
    "\n",
    "stage1_files = sorted(glob(output_dir+'*_rate.fits'))\n",
    "\n",
    "flt_groups, flt_vals = group_imgs(stage1_files, 'field_band')\n",
    "flt_groups[ flt_vals.index('MIRI1_F770W') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a82cf",
   "metadata": {},
   "source": [
    "# Make the plot for the paper\n",
    "f0 = 'jw01345001001_06101_00001_mirimage_cal.fits'\n",
    "\n",
    "# Mask and subtract a median background for the original cal image\n",
    "with fits.open('../data/reduced/' + f0) as hdu:\n",
    "    # Subtract the background\n",
    "    mask = (np.isfinite(hdu['err'].data)==False) | np.isnan(hdu['sci'].data) | hdu['dq'].data>4\n",
    "    hdu['sci'].data[mask] = 0\n",
    "    hdu['sci'].data[~mask] -= np.nanmedian( hdu['sci'].data[~mask] )\n",
    "    hdu['err'].data[mask] = np.inf\n",
    "    # Write to file\n",
    "    f1 = f0.replace('.fits','')+'_forPlot.fits'\n",
    "    hdu.writeto('../data/reduced/for_plot/'+f1, overwrite=True)\n",
    "    \n",
    "# Mask for the strmp image\n",
    "f0 = f0.replace('.fits','')+'_stprm.fits'\n",
    "# Mask and subtract a median background for the original cal image\n",
    "with fits.open('../data/reduced/' + f0) as hdu:\n",
    "    # Subtract the background\n",
    "    mask = (np.isfinite(hdu['err'].data)==False) | np.isnan(hdu['sci'].data) | hdu['dq'].data>4\n",
    "    hdu['sci'].data[mask] = 0\n",
    "    hdu['err'].data[mask] = np.inf\n",
    "    # Write to file\n",
    "    f1 = f0.replace('.fits','')+'_forPlot.fits'\n",
    "    hdu.writeto('../data/reduced/for_plot/'+f1, overwrite=True)\n",
    "    \n",
    "# Do nothing but directly copy the bgsub image\n",
    "f0 = f0.replace('.fits','')+'_bgsub.fits'\n",
    "with fits.open('../data/reduced/' + f0) as hdu:\n",
    "    # Write to file\n",
    "    f1 = f0.replace('.fits','')+'_forPlot.fits'\n",
    "    hdu.writeto('../data/reduced/for_plot/'+f1, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c61a24",
   "metadata": {},
   "source": [
    "def super_bg(f0, files, sigma_threshold=2, bw=72, bh=72, fw=5, fh=5, minarea=20,\n",
    "             kernel=np.array([[1,2,1], [2,4,2], [1,2,1]]), r_dilate=10):\n",
    "    # read in each image.  Identify objects and mask with background from SEP\n",
    "    otherfiles = []\n",
    "    for f in files :\n",
    "        if f!=f0 : otherfiles.append(f)\n",
    "    for i, f in enumerate(otherfiles) :\n",
    "        if i==0 :\n",
    "            x, y = np.shape( fits.getdata(f) )\n",
    "            darr = np.zeros( [ len(otherfiles), x, y] )\n",
    "        # Read the image\n",
    "        src, dat, wht, bkg, seg = det_src(f, sigma_threshold=sigma_threshold, r_dilate=r_dilate,\n",
    "                bw=bw, bh=bh, fw=fw, fh=fh, cr_sigclip=1., minarea=minarea, kernel=kernel)\n",
    "        print(\"%d src detected!\" %len(src))\n",
    "        # mask objects and replace with background: \n",
    "        #dat[seg > 0] = bkg.back()[seg > 0]\n",
    "        dat[seg > 0] = np.nan\n",
    "        darr[i] = dat\n",
    "        \n",
    "    #take median \n",
    "    dmed = np.nanmedian(darr, axis=0)\n",
    "    dmed[np.isnan( dmed )] = 0\n",
    "    # subtract and writeout\n",
    "    with fits.open(f0) as hdu:\n",
    "        # Subtract the background\n",
    "        hdu['sci'].data -= dmed\n",
    "        mask = (np.isfinite(hdu['err'].data)==False) | np.isnan(hdu['sci'].data) | hdu['dq'].data>4\n",
    "        hdu['sci'].data[mask] = 0\n",
    "        hdu['err'].data[mask] = np.inf\n",
    "        hdu.writeto( f0.replace('.fits','')+'_bgsub.fits', overwrite=True)\n",
    "    print(f0.replace('.fits','')+'_bgsub.fits' + \"  Done!\")\n",
    "    \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "jwst_pipeline",
   "language": "python",
   "name": "jwst_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
